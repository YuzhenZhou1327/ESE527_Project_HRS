{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the waves 4 to 15\n",
    "for wave in range(4,16):\n",
    "    # Load the Wave{wave}.csv file\n",
    "    file_path = f'wave/Wave{wave}.csv'\n",
    "    df_wave = pd.read_csv(file_path)\n",
    "    \n",
    "    # List of variables to extract\n",
    "    variables_to_extract_R = [\n",
    "        f'R{wave}SHLT',  f'R{wave}BMI', f'R{wave}MSTOT',  f'R{wave}COGTOT', \n",
    "        f'R{wave}INHPFN', f'R{wave}INHPE',  f'H{wave}HHRES', f'H{wave}CHILD', f'R{wave}LIVSIB',\n",
    "        f'H{wave}INPOV', f'H{wave}INPOVA', f'H{wave}AIRA', f'H{wave}ATOTB', f'R{wave}IEARN', f'H{wave}ITOT', f'R{wave}PENINC',\n",
    "        f'R{wave}HIGOV', f'R{wave}PRPCNT', f'R{wave}SLFEMP',f'R{wave}RETMON'\n",
    "    ]   \n",
    "\n",
    "    variables_to_extract_S = [\n",
    "        f'S{wave}SHLT', f'S{wave}BMI', f'S{wave}MSTOT',f'S{wave}COGTOT',\n",
    "        f'S{wave}INHPFN', f'S{wave}INHPE', f'H{wave}HHRES', f'H{wave}CHILD',f'S{wave}LIVSIB',\n",
    "        f'H{wave}INPOV', f'H{wave}INPOVA', f'H{wave}AIRA', f'H{wave}ATOTB', f'S{wave}IEARN', f'H{wave}ITOT', f'S{wave}PENINC',\n",
    "        f'S{wave}HIGOV', f'S{wave}PRPCNT', f'S{wave}SLFEMP', f'S{wave}RETMON'\n",
    "    ]   \n",
    "\n",
    "    # Filter the dataframe for the specified variables\n",
    "    extracted_variables_df_R = df_wave.filter(items=variables_to_extract_R)\n",
    "    extracted_variables_df_S = df_wave.filter(items=variables_to_extract_S)\n",
    "    # Export the filtered dataframe to a new CSV file\n",
    "    extracted_variables_df_R.to_csv(f'extract_features/extracted_variables_wave{wave}_R{wave}.csv', index=False)\n",
    "    extracted_variables_df_S.to_csv(f'extract_features/extracted_variables_wave{wave}_S{wave}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns of the extracted variables\n",
    "def rename_columns(file_path, wave):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = [re.sub(r'R\\d+|S\\d+', '', col) for col in df.columns]\n",
    "    df.columns = [re.sub(r'H\\d+', 'H', col) for col in df.columns]\n",
    "    return df.to_csv(f'{file_path}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the waves 4 to 15\n",
    "for wave in range(4,16):\n",
    "    rename_columns(f'extract_features/extracted_variables_wave{wave}_R{wave}.csv', wave)\n",
    "    rename_columns(f'extract_features/extracted_variables_wave{wave}_S{wave}.csv', wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through wave numbers from 4 to 15\n",
    "for wave in range(4, 16):\n",
    "    # For each wave, there are two files, one for R and one for S\n",
    "    for prefix in ['R', 'S']:\n",
    "        # Construct the file path for the current wave and prefix\n",
    "        file_path = f'extract_features/extracted_variables_wave{wave}_{prefix}{wave}.csv'\n",
    "        \n",
    "        # Load the current CSV file into a DataFrame\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Concatenate the temporary DataFrame with the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_file_path = 'combined_extracted_variables_wave4to15.csv'\n",
    "combined_df.to_csv(output_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(file_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop rows with any missing values\n",
    "    df_cleaned = df.dropna()\n",
    "    \n",
    "    # Save the cleaned data to a new CSV file\n",
    "    df_cleaned.to_csv('cleaned_extracted_data.csv', index=False)\n",
    "    \n",
    "    # Print a message to indicate the process is complete\n",
    "    print(f'Data cleaning complete. The cleaned file is saved as {file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete. The cleaned file is saved as combined_extracted_variables_wave4to15.csv\n"
     ]
    }
   ],
   "source": [
    "data_cleaning('combined_extracted_variables_wave4to15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SHLT   BMI  MSTOT  COGTOT  INHPFN  INHPE  HHHRES  HCHILD  LIVSIB  HINPOV  \\\n",
      "0   2.0  43.0   14.0    23.0     0.0    0.0     3.0     3.0     4.0     0.0   \n",
      "1   2.0  21.6   15.0    29.0     0.0    0.0     2.0     2.0     1.0     0.0   \n",
      "2   1.0  24.3   15.0    28.0     0.0    0.0     2.0     3.0     1.0     0.0   \n",
      "3   2.0  24.0   15.0    23.0     0.0    0.0     2.0     2.0     1.0     0.0   \n",
      "4   4.0  22.0    8.0    19.0     1.0    0.0     2.0     3.0     2.0     0.0   \n",
      "\n",
      "   HINPOVA     HAIRA     HATOTB    IEARN          HITOT  PENINC  HIGOV  \\\n",
      "0      0.0  200000.0   324000.0      0.0   57024.000000     1.0    1.0   \n",
      "1      0.0  600000.0  1171000.0  15000.0   46652.000000     1.0    1.0   \n",
      "2      0.0  917000.0  2275000.0  75000.0  180500.000000     0.0    1.0   \n",
      "3      0.0   30000.0   438000.0   8000.0   55673.367584     1.0    0.0   \n",
      "4      0.0       0.0       30.0  11700.0   23148.000000     0.0    1.0   \n",
      "\n",
      "   PRPCNT  SLFEMP  RETMON  \n",
      "0     0.0     0.0       1  \n",
      "1     0.0     0.0       1  \n",
      "2     1.0     1.0       1  \n",
      "3     1.0     0.0       1  \n",
      "4     0.0     0.0       1  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('cleaned_extracted_data.csv')\n",
    "\n",
    "# Convert 'RETMON' column: 1 where there are values (not NaN) and 0 otherwise\n",
    "data['RETMON'] = data['RETMON'].notnull().astype(int)\n",
    "\n",
    "# Save the modified dataframe back to a new CSV file, if needed\n",
    "data.to_csv('cleaned_extracted_data.csv', index=False)  # Change this to your desired output file path\n",
    "\n",
    "# To check the first few rows to confirm the changes, you can print them\n",
    "print(data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
