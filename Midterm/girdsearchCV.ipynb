{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error',  # or 'r2' for R² score\n",
    "                           cv=10,  # Number of folds in cross-validation\n",
    "                           n_jobs=-1,  # Use all available CPUs\n",
    "                           verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHLT</th>\n",
       "      <th>BMI</th>\n",
       "      <th>MSTOT</th>\n",
       "      <th>COGTOT</th>\n",
       "      <th>INHPFN</th>\n",
       "      <th>HHHRES</th>\n",
       "      <th>HCHILD</th>\n",
       "      <th>LIVSIB</th>\n",
       "      <th>HINPOV</th>\n",
       "      <th>HAIRA</th>\n",
       "      <th>HATOTB</th>\n",
       "      <th>IEARN</th>\n",
       "      <th>HITOT</th>\n",
       "      <th>PENINC</th>\n",
       "      <th>HIGOV</th>\n",
       "      <th>PRPCNT</th>\n",
       "      <th>SLFEMP</th>\n",
       "      <th>RETMON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>22400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>134384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16477.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>72157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>138300.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>95660.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33533</th>\n",
       "      <td>4.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27500.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>29112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33534</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33535</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33536</th>\n",
       "      <td>4.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33537</th>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33538 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SHLT   BMI  MSTOT  COGTOT  INHPFN  HHHRES  HCHILD  LIVSIB  HINPOV  \\\n",
       "0       5.0  33.0   14.0    17.0     0.0     2.0     4.0     0.0     0.0   \n",
       "1       4.0  23.8    8.0    14.0     0.0     2.0     6.0     2.0     0.0   \n",
       "2       3.0  26.0   15.0    27.0     0.0     2.0     2.0     1.0     0.0   \n",
       "3       4.0  40.7   11.0    16.0     0.0     3.0     4.0     7.0     0.0   \n",
       "4       3.0  22.8   15.0    31.0     0.0     4.0     4.0     4.0     0.0   \n",
       "...     ...   ...    ...     ...     ...     ...     ...     ...     ...   \n",
       "33533   4.0  39.6   14.0    23.0     0.0     2.0     5.0     6.0     1.0   \n",
       "33534   1.0  18.4   14.0    27.0     0.0     5.0     6.0     5.0     1.0   \n",
       "33535   1.0  26.9    9.0    25.0     0.0     2.0     7.0     7.0     1.0   \n",
       "33536   4.0  29.3   13.0    23.0     0.0     3.0     3.0     7.0     1.0   \n",
       "33537   3.0  30.0   12.0    25.0     0.0     2.0     3.0    10.0     1.0   \n",
       "\n",
       "         HAIRA    HATOTB     IEARN     HITOT  PENINC  HIGOV  PRPCNT  SLFEMP  \\\n",
       "0          0.0       0.0   20000.0   22400.0     0.0    0.0     0.0     0.0   \n",
       "1          0.0   15000.0   25000.0  107000.0     0.0    0.0     1.0     0.0   \n",
       "2      40000.0  290000.0  103000.0  134384.0     0.0    0.0     1.0     0.0   \n",
       "3          0.0   16477.0   62000.0   72157.0     0.0    0.0     0.0     0.0   \n",
       "4       4000.0  138300.0   15000.0   95660.0     0.0    0.0     1.0     0.0   \n",
       "...        ...       ...       ...       ...     ...    ...     ...     ...   \n",
       "33533      0.0   27500.0   27000.0   29112.0     0.0    0.0     0.0     0.0   \n",
       "33534      0.0   90000.0       0.0       0.0     0.0    0.0     1.0     0.0   \n",
       "33535      0.0    2341.0    3295.0    3295.0     0.0    0.0     1.0     0.0   \n",
       "33536      0.0       0.0   18000.0   18000.0     0.0    0.0     0.0     0.0   \n",
       "33537      0.0   77000.0       0.0       0.0     0.0    0.0     1.0     0.0   \n",
       "\n",
       "       RETMON  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "33533       0  \n",
       "33534       0  \n",
       "33535       0  \n",
       "33536       0  \n",
       "33537       0  \n",
       "\n",
       "[33538 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Removed_outliers_byGroup_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0, 0, 0, 0, 0', '0, 0, 0, 0, 1', '0, 0, 1, 0, 0', '0, 0, 1, 0, 1',\n",
       "       '0, 0, 1, 1, 0', '0, 0, 1, 1, 1', '0, 1, 1, 0, 0', '0, 1, 1, 1, 0',\n",
       "       '0, 1, 1, 1, 1', '1, 0, 0, 0, 0'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['group'] = df.apply(lambda row: f\"{int(row['HINPOV'])}, {int(row['PENINC'])}, {int(row['HIGOV'])}, {int(row['RETMON'])}, {int(row['SLFEMP'])}\", axis=1)\n",
    "groups = df['group'].unique()\n",
    "models = {}\n",
    "performance = {}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['SHLT', 'COGTOT', 'MSTOT']\n",
    "continuous_features = ['BMI', 'INHPFN',  'HHHRES', 'HCHILD','LIVSIB',  'HAIRA', 'HATOTB', 'IEARN','HITOT', 'PRPCNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.00.00.00.0 and target SHLT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.00.00.00.0 and target SHLT: 0.28471086284429453\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.00.00.00.0 and target COGTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.00.00.00.00.0 and target COGTOT: 4.922834664839798\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.00.00.00.0 and target MSTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.00.00.00.0 and target MSTOT: 0.9969194022859285\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.00.00.01.0 and target SHLT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.00.00.01.0 and target SHLT: 0.29567518433221646\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.00.00.01.0 and target COGTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.00.00.01.0 and target COGTOT: 3.6595303440496334\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.00.00.01.0 and target MSTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.00.00.01.0 and target MSTOT: 0.8187545121263395\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.00.00.0 and target SHLT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.00.00.0 and target SHLT: 0.2546716551911689\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.00.00.0 and target COGTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.00.00.0 and target COGTOT: 5.37689443959137\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.00.00.0 and target MSTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.00.01.00.00.0 and target MSTOT: 1.2537996905075195\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.00.01.0 and target SHLT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.00.01.00.01.0 and target SHLT: 0.29246535108481264\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.00.01.0 and target COGTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.00.01.0 and target COGTOT: 5.51718610563226\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.00.01.0 and target MSTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.00.01.00.01.0 and target MSTOT: 0.8207136587771204\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.01.00.0 and target SHLT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.01.00.0 and target SHLT: 0.26030239988246606\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.01.00.0 and target COGTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.01.00.0 and target COGTOT: 4.325075279825279\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.01.00.0 and target MSTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.01.00.0 and target MSTOT: 1.0318997269997272\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.01.01.0 and target SHLT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.01.01.0 and target SHLT: 0.29893065843621397\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.01.01.0 and target COGTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MSE for group 0.00.01.01.01.0 and target COGTOT: 4.3026340054289225\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.00.01.01.01.0 and target MSTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.00.01.01.01.0 and target MSTOT: 0.9952179199401422\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.00.00.0 and target SHLT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MSE for group 0.01.01.00.00.0 and target SHLT: 0.376628813559322\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.00.00.0 and target COGTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.01.01.00.00.0 and target COGTOT: 6.916735905138616\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.00.00.0 and target MSTOT: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.01.01.00.00.0 and target MSTOT: 1.1485793715696258\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.01.00.0 and target SHLT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.01.01.01.00.0 and target SHLT: 0.20784992241476952\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.01.00.0 and target COGTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 0.01.01.01.00.0 and target COGTOT: 3.851208032619776\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.01.00.0 and target MSTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.01.01.01.00.0 and target MSTOT: 0.8106730087138817\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.01.01.0 and target SHLT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.01.01.01.01.0 and target SHLT: 0.20189133668301695\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.01.01.0 and target COGTOT: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.01.01.01.01.0 and target COGTOT: 4.18824022887324\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 0.01.01.01.01.0 and target MSTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MSE for group 0.01.01.01.01.0 and target MSTOT: 0.6136049756716099\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 1.00.00.00.00.0 and target SHLT: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 1.00.00.00.00.0 and target SHLT: 0.5714059475271207\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 1.00.00.00.00.0 and target COGTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MSE for group 1.00.00.00.00.0 and target COGTOT: 11.845587719298244\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best parameters for group 1.00.00.00.00.0 and target MSTOT: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "MSE for group 1.00.00.00.00.0 and target MSTOT: 3.0226155945419104\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    # Filter data for the current group\n",
    "    group_data = df[df['group'] == group]\n",
    "    \n",
    "    # Split the group data into features and targets\n",
    "    X = group_data[['BMI', 'INHPFN',  'HHHRES', 'HCHILD','LIVSIB',  'HAIRA', 'HATOTB', 'IEARN','HITOT', 'PRPCNT']]\n",
    "    y = group_data[['SHLT', 'COGTOT', 'MSTOT']]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Train a model for each target\n",
    "    for target in y_train.columns:\n",
    "        # Initialize the RandomForestRegressor\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        \n",
    "        # Perform the search\n",
    "        grid_search.fit(X_train, y_train[target])\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Predict using the best model\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Calculate the performance\n",
    "        mse = mean_squared_error(y_test[target], y_pred)\n",
    "        \n",
    "        # Store the best model and its performance\n",
    "        models[(group, target)] = best_model\n",
    "        performance[(group, target)] = mse\n",
    "        \n",
    "        # Print the best parameters for this group and target\n",
    "        print(f\"Best parameters for group {group} and target {target}: {grid_search.best_params_}\")\n",
    "        print(f\"MSE for group {group} and target {target}: {mse}\")\n",
    " \n",
    "# Now 'models' contains the best model for each target within each group,\n",
    "# and 'performance' contains the MSE for these models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
